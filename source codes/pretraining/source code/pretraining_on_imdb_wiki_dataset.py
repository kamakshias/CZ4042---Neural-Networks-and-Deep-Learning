# -*- coding: utf-8 -*-
"""Pretraining on IMDB-Wiki Dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15MgMKkaV7bo63HF_Hs3F0AEgkn0D0JfS
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.io import read_file
from matplotlib import image
from matplotlib import pyplot
from PIL import Image
from numpy import asarray
from keras.regularizers import l2
import numpy as np
import pandas as pd
import time
from tensorflow.image import resize
import tensorflow.keras.backend as K
import matplotlib.pyplot as plt
import multiprocessing as mp
import statistics
import math

from sklearn import preprocessing
from sklearn.model_selection import KFold
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import Callback
from keras.preprocessing.image import load_img

from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, Lambda
from tensorflow.keras import Sequential
from keras.regularizers import l2
from tensorflow.keras import layers

from tensorflow.keras.callbacks import Callback
from keras.callbacks import ModelCheckpoint
from keras.callbacks import EarlyStopping


df = pd.read_csv('/home/UG/atrik001/imdb.csv')
df.drop(df.index[20001:], 0, inplace=True)
print(len(df))

age_buckets = []
for i in range(len(df)):
    if int(df['ages'][i]) in range(0, 4):
        age = 0
    elif int(df['ages'][i]) in range(4, 8):
        age = 1
    elif int(df['ages'][i]) in range(8, 15):
        age = 2
    elif int(df['ages'][i]) in range(15, 25):
        age = 3
    elif int(df['ages'][i]) in range(25, 38):
        age = 4
    elif int(df['ages'][i]) in range(38, 48):
        age = 5
    elif int(df['ages'][i]) in range(48, 60):
        age = 6
    elif int(df['ages'][i]) >= 60:
        age = 7
    age_buckets.append(age)

df['age_buckets'] = age_buckets

df_image_x = []
df_gender_y = []
df_age_y = []
for i in range(len(df)):
    image = Image.open('/home/UG/atrik001/imdb_crop/' +
                       str(df['img_paths'][i]))
    image = image.convert('RGB')
    image = np.array(image)
    image = tf.image.resize(image, [256, 256])
    data = asarray(image)
    for j in data:
        j = j/255
    df_image_x.append(data)
    df_gender_y.append(df['genders'][i])
    df_age_y.append(df['age_buckets'][i])

print(len(df_image_x))

x_train, x_val, x_test = df_image_x[0:59500], df_image_x[59500:72250], df_image_x[72250:85000]

y_train, y_val, y_test = df_age_y[0:59500], df_age_y[59500:72250], df_age_y[72250:85000]

x_train = np.asarray(x_train, dtype='float32')
y_train = np.asarray(y_train, dtype='float32')
x_val = np.asarray(x_val, dtype='float32')
y_val = np.asarray(y_val, dtype='float32')
x_test = np.asarray(x_test, dtype='float32')
y_test = np.asarray(y_test, dtype='float32')


def step_decay(epoch):
    init_lrate = 1e-3  # TOCHANGE
    drop = 0.1
    epochs_drop = 10000
    lrate = init_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))
    return lrate


# Definition of weight initializers, optimizers, loss function and learning rate
weight_init = keras.initializers.TruncatedNormal(
    mean=0.0, stddev=0.01, seed=10)
sgd = keras.optimizers.SGD(learning_rate=0.001, momentum=0.0)  # TOCHANGE
loss_func = 'sparse_categorical_crossentropy'
lrate = keras.callbacks.LearningRateScheduler(step_decay)

age_model = keras.models.Sequential([
    Conv2D(96, (7, 7), input_shape=(256, 256, 3), strides=4,
           padding='valid', activation='relu', kernel_initializer=weight_init),
    MaxPooling2D(pool_size=(3, 3), strides=2, padding='same'),
    Lambda(lambda x: tf.nn.local_response_normalization(
        input=x, alpha=0.0001, beta=0.75)),

    Conv2D(256, (5, 5), padding='same', activation='relu',
           kernel_initializer=weight_init),
    MaxPooling2D(pool_size=(3, 3), strides=2, padding='same'),
    Lambda(lambda x: tf.nn.local_response_normalization(
        input=x, alpha=0.0001, beta=0.75)),

    Conv2D(384, (3, 3), padding='same', activation='relu',
           kernel_initializer=weight_init),
    MaxPooling2D(pool_size=(3, 3), strides=2, padding='same'),
    Flatten(),

    Dense(512, activation="relu", kernel_initializer=weight_init),
    Dropout(0.5),

    Dense(512, activation='relu', kernel_initializer=weight_init),
    Dropout(0.5),

    Dense(8, activation='softmax', kernel_initializer=weight_init)
])

age_model.compile(loss=loss_func, optimizer=sgd, metrics=['accuracy'])

num_epochs = 200
batch_size = 4
seed = 10
save_model = True
np.random.seed(seed)
tf.random.set_seed(seed)
drive_prefix = "/home/UG/atrik001/pretrained models"
checkpoint = keras.callbacks.ModelCheckpoint(
    drive_prefix + '/pretrained_checkpoint_age.h5', monitor='val_accuracy', verbose=1, mode='max', save_best_only=True)
csv_logger = keras.callbacks.CSVLogger(
    drive_prefix + '/pretrained_csvlog_age.csv')
early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=30)
if save_model:
    callbacks = [lrate, checkpoint, csv_logger, early_stopping]
else:
    callbacks = [lrate, csv_logger, early_stopping]

# Train the model
age_model.summary()
results = age_model.fit(x_train, y_train,
                        batch_size=batch_size,
                        epochs=num_epochs,
                        verbose=1,
                        use_multiprocessing=True,
                        callbacks=callbacks,
                        validation_data=(x_val, y_val))
